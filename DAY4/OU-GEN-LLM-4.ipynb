{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0601f059-244b-4b7e-9fdd-3ae48a215e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def f1(fname): # load json to documents in llm - dataloading\n",
    "    with open(fname) as fobj:\n",
    "        data = json.load(fobj)\n",
    "\n",
    "    docs = []\n",
    "    for var in data:\n",
    "        content = var.get(\"content\",\" \")\n",
    "        metadata_result = {k: v for k,v, in var.items() if k != 'content'}\n",
    "        docs.append(Document(page_content=content,metadata=metadata_result))\n",
    "    return docs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c526f90-f3f6-43fe-a0ca-a7ea25a5b505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'LangChain Overview'}, page_content='LangChain is a framework for developing applications powered by language models.'),\n",
       " Document(metadata={'title': 'What is Ollama?'}, page_content='Ollama allows running large language models locally like LLaMA and Mistral.'),\n",
       " Document(metadata={'title': 'Embeddings in NLP'}, page_content='Embeddings are vector representations of text used for similarity and retrieval.')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = f1('data.json')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ac9febd-5f24-4bd9-a81c-6368694ebebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76a4903-5fcc-40b9-8557-4a633e86b2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\AppData\\Local\\Temp\\ipykernel_20172\\933803318.py:4: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding = OllamaEmbeddings(model=\"gemma:2b\")\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300,chunk_overlap=50)\n",
    "splitted_docs = splitter.split_documents(data)\n",
    "\n",
    "embedding = OllamaEmbeddings(model=\"gemma:2b\")\n",
    "\n",
    "vectordb = Chroma.from_documents(splitted_docs,embedding=embedding)\n",
    "retriver = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c88deba-a75c-4321-886d-8d50b3b9b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain \n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6543ffca-6a82-45a4-816e-5ec6a595f1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'what is langchain?', 'context': [Document(metadata={'title': 'LangChain Overview'}, page_content='LangChain is a framework for developing applications powered by language models.'), Document(metadata={'title': 'What is Ollama?'}, page_content='Ollama allows running large language models locally like LLaMA and Mistral.'), Document(metadata={'title': 'Embeddings in NLP'}, page_content='Embeddings are vector representations of text used for similarity and retrieval.')], 'answer': \"Sure, here's a summary of the answer:\\n\\n**LangChain** is a framework for developing applications powered by language models. It allows users to run large language models locally, enabling them to build and deploy various applications that leverage the capabilities of these models.\"}\n"
     ]
    }
   ],
   "source": [
    "# define your prompt\n",
    "prompt_obj = PromptTemplate.from_template('''You are an expert assistant {context} Question:{input} Answer:''')\n",
    "# connect llm\n",
    "llm_obj = Ollama(model='gemma:2b')\n",
    "\n",
    "# create stuff chain to combine retrived docs\n",
    "doc_chain = create_stuff_documents_chain(llm=llm_obj,prompt=prompt_obj)\n",
    "# create retrieved chain\n",
    "rag_chain = create_retrieval_chain(retriever=retriver,combine_docs_chain=doc_chain)\n",
    "\n",
    "# invoke query\n",
    "response = rag_chain.invoke({'input':'what is langchain?'})\n",
    "# display response\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ded207a-b800-4c39-92ed-a0ff1a82ac9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': \"Sure, here's a summary of the answer:\\n\"\n",
      "           '\\n'\n",
      "           '**LangChain** is a framework for developing applications powered '\n",
      "           'by language models. It allows users to run large language models '\n",
      "           'locally, enabling them to build and deploy various applications '\n",
      "           'that leverage the capabilities of these models.',\n",
      " 'context': [Document(metadata={'title': 'LangChain Overview'}, page_content='LangChain is a framework for developing applications powered by language models.'),\n",
      "             Document(metadata={'title': 'What is Ollama?'}, page_content='Ollama allows running large language models locally like LLaMA and Mistral.'),\n",
      "             Document(metadata={'title': 'Embeddings in NLP'}, page_content='Embeddings are vector representations of text used for similarity and retrieval.')],\n",
      " 'input': 'what is langchain?'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f703e201-72ed-4af3-ae3c-ea0dcb1b7394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Sure, here's a summary of the answer:\\n\"\n",
      " '\\n'\n",
      " '**LangChain** is a framework for developing applications powered by language '\n",
      " 'models. It allows users to run large language models locally, enabling them '\n",
      " 'to build and deploy various applications that leverage the capabilities of '\n",
      " 'these models.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b227176b-1413-40c2-bdd6-5b3959717b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'what is langchain?', 'context': [Document(metadata={'title': 'LangChain Overview'}, page_content='LangChain is a framework for developing applications powered by language models.'), Document(metadata={'title': 'What is Ollama?'}, page_content='Ollama allows running large language models locally like LLaMA and Mistral.'), Document(metadata={'title': 'Embeddings in NLP'}, page_content='Embeddings are vector representations of text used for similarity and retrieval.')], 'answer': 'The context does not provide any information about what langchain is, so I cannot answer this question from the provided context.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chat_prompt = ChatPromptTemplate.from_messages([('system','you are exper assistant. use the below context to answer the question'),\n",
    "                                  ('human','content:\\n{context}\\n\\nQuestion: {input}')])\n",
    "\n",
    "llmobj = Ollama(model=\"gemma:2b\")\n",
    "\n",
    "doc_chain = create_stuff_documents_chain(llm=llmobj,prompt=chat_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever=retriver,combine_docs_chain=doc_chain)\n",
    "\n",
    "# invoke query\n",
    "response = rag_chain.invoke({'input':'what is langchain?'})\n",
    "# display response\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3101cb-f1e7-4b9b-a8ca-c2cae9485325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
