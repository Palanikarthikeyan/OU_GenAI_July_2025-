{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ac4367-e4c6-498a-aee8-704143886f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "!streamlit run p6.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0282f5e3-94a7-4c0a-98fb-92f64f537007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app_huggingfaceembedding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe8cc92-b8b3-4bc7-8bf1-1f51c963b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "#from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c19f880d-0e62-4221-98e0-22de8817f9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b935639e-646b-46a6-95e4-d38d4a26eb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\AppData\\Local\\Temp\\ipykernel_23216\\840512378.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90cee897-5d3c-4b0a-b5dd-efbd70a2db14",
   "metadata": {},
   "source": [
    "PyPDFDirectoryLoader(\"docs\").load() #OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b6ebb80-5bcb-41b6-a73d-c6b33c23bf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredWordDocumentLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e452454-fb6c-4d39-a3b3-2c92c4b86cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-docx) (5.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-docx) (4.12.2)\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a056e93e-8b99-491a-b520-168845313c51",
   "metadata": {},
   "source": [
    "UnstructuredWordDocumentLoader('PSA.docx').load()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "337adbb9-2e59-4426-b747-f70aa6ba0946",
   "metadata": {},
   "source": [
    "from langchain.document_loaders import UnstructuredWordDocumentLoader\n",
    "\n",
    "fname=\"PSA.docx\"\n",
    "loader = UnstructuredWordDocumentLoader(fname)\n",
    "docs = loader.load()\n",
    "for var in docs:\n",
    "    print(var.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390ab41f-7daf-4255-abc0-423f1df2aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PyPDFLoader(\"dir1\") -> dir1/pdf file\n",
    "dir2/p1.pdf p1.docx p1.csv p1.txt\n",
    "    .............................\n",
    "# apply python code logic - if pre-defined loader is not exists \n",
    "# ----------------\n",
    "\n",
    "p1.pdf  -> call   PyPDFLoader(p1.pdf)\n",
    "p1.docx  -> call  UnstructuredDocumentLoader(p1.docx)\n",
    "p1.csv   -> call  CSVLoader(p1.csv)\n",
    "..\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc57b7dc-15e8-43dc-ac9d-13f1919df0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object walk at 0x000001ABEE728BC0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\".\")\n",
    "os.walk(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1ea3e95-be86-45de-b247-c9a4369eadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY']=os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35fc5f2f-b096-46cd-a116-06c6aacdaed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karth\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "C:\\Users\\karth\\AppData\\Roaming\\Python\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer is a neural network architecture primarily used for natural language processing (NLP) tasks, introduced in a research paper by Vaswani et al. in 2017. It's a type of encoder-decoder model that revolutionized the field of NLP by achieving state-of-the-art results in various tasks, such as machine translation, text summarization, and language modeling.\n",
      "\n",
      "The Transformer architecture is designed to process input sequences (e.g., sentences or paragraphs) in parallel, rather than sequentially, as in traditional recurrent neural networks (RNNs). This allows it to:\n",
      "\n",
      "1. **Parallelize computation**: By processing all positions in the input sequence simultaneously, the Transformer can leverage modern computing architectures and achieve faster processing times.\n",
      "2. **Avoid the vanishing gradient problem**: In traditional RNNs, the gradients used to update the model's parameters can become very small as they propagate through time, making it difficult to train deep networks. The Transformer's parallel architecture eliminates this problem.\n",
      "3. **Improve performance**: By leveraging self-attention mechanisms, the Transformer can model complex relationships between input elements more effectively than traditional RNNs.\n",
      "\n",
      "The Transformer architecture consists of an encoder and a decoder:\n",
      "\n",
      "1. **Encoder**: The encoder takes in a sequence of tokens (e.g., words or characters) and produces a continuous representation of the input sequence.\n",
      "2. **Decoder**: The decoder takes the output from the encoder and generates the output sequence, one token at a time.\n",
      "\n",
      "The Transformer's key components are:\n",
      "\n",
      "1. **Self-attention mechanisms**: These allow the model to attend to different positions in the input sequence simultaneously, weighing their importance.\n",
      "2. **Multi-head attention**: This is a technique that allows the model to jointly attend to information from different representation subspaces at different positions.\n",
      "3. **Positional encoding**: This is a mechanism used to inject positional information into the input sequence, allowing the model to understand the relative position of each element.\n",
      "\n",
      "The Transformer has been widely adopted in various NLP applications, and its variants have achieved state-of-the-art results in many tasks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('attention.pdf')\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore=FAISS.from_documents(documents=splits,embedding=embeddings)\n",
    "retriver = vectorstore.as_retriever()\n",
    "v=(\"You are AI assistant\\n\\n {context}\")\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\",v),(\"human\",\"{input}\")])\n",
    "\n",
    "chain = create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain = create_retrieval_chain(retriver,chain)\n",
    "response = rag_chain.invoke({'input':'what is transformer?'})\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f28f8d54-18f9-4ed8-9a3a-ab2e2210992c",
   "metadata": {},
   "source": [
    "DuckDuckGoSearchRun - tool - search engine \n",
    "llm ->model1 - up-to-date\n",
    "       |\n",
    "      DuckDuckGoSearchRun tool \n",
    "\n",
    "https://www.promptingguide.ai/research/llm-agents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
